\section{Overview}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Overview}
  
  \begin{itemize}
    \item What happens as $T\rightarrow \infty$?
    \item Consistency: choose ``best'' model wpa 1
    \item Efficiency: procedure with good risk properties
    \item Can't have both at once.
    \item Large, fairly technical literature: only a brief overview today. 
    \item More details: Sin and White (1992, 1996), P\"{o}tscher (1991), Leeb \& P\"{o}tscher (2005), Yang (2005) and Yang (2007).
  \end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Penalizing the Likelihood}
  
  \begin{block}{Examples we've seen:}
	\begin{eqnarray*}
		 TIC &=& 2\ell_T(\widehat{\theta}) -\mbox{trace}\left\{\widehat{J}^{-1} \widehat{K} \right\}\\
		AIC &=& 2\ell_T(\widehat{\theta}) - 2\; \mbox{length}(\theta)\\
		BIC &=& 2\ell_T(\widehat{\theta}) - \log(T)\; \mbox{length}(\theta)
	\end{eqnarray*}

  \begin{block}{Generic penalty $c_{T,k}$}
    \[IC(M_k) = 2 \sum_{t=1}^T \log f_{k,t}(Y_t| \widehat{\theta_k}) - c_{T,k}\]
  \end{block}

  \begin{alertblock}{How does choice of $c_{T,k}$ affect behavior of the criterion?}
  \end{alertblock}


  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Weak Consistency}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Weak Consistency: Suppose $\text{M}_{k_0}$ Uniquely Minimizes KL}
  
  \begin{block}{Assumption}

    \vspace{-1em}
	$$\underset{T\rightarrow \infty}{\lim\inf}\left(\underset{k \neq k_0}{\min} \frac{1}{T}\sum_{t = 1}^T \left\{ KL(g; f_{k,t}) - KL(g;f_{k_0,t}) \right\} \right) > 0$$
  \end{block}

  \begin{block}{Consequences}
    \begin{itemize}
      \item Any criterion with $c_{T,k}> 0$ and $c_{T,k} = o_p(T)$ is weakly consistent: \alert{selects $\text{M}_{k_0}$ wpa 1 in the limit}.
      \item Weak consistency still holds if $c_{T,k}$ is zero for one of the models, so long as it is strictly positive for all the others.
    \end{itemize}
  \end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Both AIC and BIC are Weakly Consistent}
  
AIC and BIC are Weakly Consistent: both satisfy $T^{-1}c_{T,k} \overset{p}{\rightarrow} 0$.
	\begin{eqnarray*}
		\mbox{BIC Penalty:}&& c_{T,k} = \log(T) \times \mbox{length}(\theta_k)\\
		\mbox{AIC Penalty:} && c_{T,k} = 2\times \mbox{length}(\theta_k)
	\end{eqnarray*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Consistency}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Consistency}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frametitle{Efficiency}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Efficiency}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{AIC versus BIC in a Simple Example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Consistency versus Efficiency in a Simple Example}

  \begin{block}{Information Criteria}
    Consider criteria of the form $\text{IC}_m = 2\ell(\theta) - d_T \times \text{length}(\theta)$.
  \end{block}
  
  
  \begin{block}{True DGP}
  $Y_{1}, \dots, Y_T \sim \mbox{iid N}(\mu, 1)$
  \end{block}

  \pause

  \begin{block}{Candidate Models}
    $\text{M}_0$ assumes $\mu = 0$, $\text{M}_1$ does not restrict $\mu$. Only one parameter:

    \vspace{-1em}
  \begin{align*}
    \text{IC}_0 &= 2 \max_\mu \left\{ \ell(\mu) \colon \text{M}_0 \right\} \\ 
    \text{IC}_1 &= 2 \max_\mu \left\{ \ell(\mu) \colon \text{M}_1 \right\} - d_T
  \end{align*}
  \end{block}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{Log-Likelihood Function}

  Since $\; \alert{\sum_{t=1}^T (Y_t -\mu)^2 = T(\bar{Y} - \mu)^2 + T \widehat{\sigma}^2}$,

\begin{eqnarray*}
	\ell_T(\mu)&=& \sum_{t=1}^T \log \left( \frac{1}{2\pi} \exp \left\{-\frac{1}{2}(Y_t - \mu)^2 \right\}\right)\\
  &=& -\frac{T}{2} \log\left( 2\pi \right) - \frac{1}{2} \sum_{t=1}^{T} (Y_t - \mu)^2\\
  &=& -\frac{T}{2} \log\left( 2\pi \right) - \frac{T}{2} \widehat{\sigma}^2 - \frac{T}{2}(\bar{Y} - \mu)^2\\
  &=& \text{Constant} - \frac{T}{2}(\bar{Y} - \mu)^2
\end{eqnarray*}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Side Calculation: \normalsize $\sum_{t=1}^T (Y_t -\mu)^2 = T(\bar{Y} - \mu)^2 + T \widehat{\sigma}^2$}

\scriptsize
\begin{eqnarray*}
  T\widehat{\sigma}^2 &=& \sum_{t=1}^T \left(Y_t - \bar{Y}\right)^2 = \sum_{t=1}^T \left(Y_t - \mu + \mu - \bar{Y}\right)^2 = \sum_{t=1}^T \left[(Y_t -\mu) - (\bar{Y} - \mu)\right]^2\\
		&=&\sum_{t=1}^T (Y_t -\mu)^2 - \sum_{t=1}^T 2(Y_t -\mu)(\bar{Y} - \mu) + \sum_{t=1}^T (\bar{Y} - \mu)^2\\
				&=& \left[  \sum_{t=1}^T \left(Y_t - \mu\right)^2\right]   - 2(\bar{Y} - \mu) \left( \sum_{t=1}^T Y_t- \sum_{t=1}^T \mu \right)+T(\bar{Y} - \mu)^2\\
				&=& \left[  \sum_{t=1}^T \left(Y_t - \mu\right)^2\right]   - 2(\bar{Y} - \mu)(T\bar{Y}-T\mu)+T(\bar{Y} - \mu)^2\\
				&=&\left[  \sum_{t=1}^T \left(Y_t - \mu\right)^2\right]   - 2T(\bar{Y} - \mu)^2+T(\bar{Y} - \mu)^2\\
				&=&\left[  \sum_{t=1}^T \left(Y_t - \mu\right)^2\right]   - T(\bar{Y} - \mu)^2
\end{eqnarray*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Selected Model $\widehat{\text{M}}$}

  \begin{block}{Information Criteria}
  M$_0$ sets $\mu=0$ while M$_1$ uses the MLE $\bar{Y}$, so we have
  \vspace{1em}
  \begin{align*}
    \text{IC}_0 &= 2 \max_\mu \left\{ \ell(\mu) \colon \text{M}_0 \right\} = 2 \times \text{Constant} - T\bar{Y}^2\\ 
    \text{IC}_1 &= 2 \max_\mu \left\{ \ell(\mu) \colon \text{M}_1 \right\} = 2 \times \text{Constant} - d_T\\ 
  \end{align*}
\end{block}

\vspace{-2em}

  \begin{block}{Difference of Criteria}
    \vspace{-1em}
  \[
    \text{IC}_1 - \text{IC}_0 = T \bar{Y}^2 - d_T
  \]
\end{block}

\vspace{-1em}

  \begin{block}{Selected Model}
    \vspace{-1em}
   \[
     \widehat{\text{M}} = \left\{
       \begin{array}{cc}
         \text{M}_1, & |\sqrt{T} \bar{Y}| \geq \sqrt{d_T}\\
         \text{M}_0, & |\sqrt{T} \bar{Y}| \leq \sqrt{d_T}
       \end{array}
       \right.
   \]
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Case I: $\mu \neq 0$}
  \framesubtitle{Apply theory from earlier in lecture\dots}

  \begin{block}{KL-Divergence of $\text{M}_1$}
    $\text{M}_1$ is the true DGP with minimized KL-divergence equal to zero.
  \end{block}

  \begin{block}{KL-Divergence of $\text{M}_0$}
    \begin{itemize}
      \item Truth: $g(y) = (2\pi)^{-1/2}\exp\left\{ -(y-\mu)^2/2 \right\}$ 
      \item $\text{M}_0$: $f(y) = (2\pi)^{-1/2}\exp\left\{ -y^2/2\right\}$ 
      \item Hence: $\log g(y) - \log f(y) = -\frac{1}{2}(y-\mu)^2 + \frac{1}{2}y^2
          = \mu \left(y - \frac{\mu}{2}\right)$
    \end{itemize}

    \vspace{-1em}
          \begin{align*}
          \text{KL}(g;\text{M}_0) &= \int_{\mathbb{R}}\mu(y - \mu/2) (2\pi)^{-1/2}\exp\left\{ (y-\mu)^2/2 \right\}\; \text{d}y \\
          &= \mu(\mu - \mu/2) = \mu^2 /2
        \end{align*}
  \end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Verifying Weak Consistency: $\mu \neq 0$}

  \begin{block}{Condition on KL-Divergence}
  \small
  \vspace{-2em}
  \[
    \underset{T\rightarrow \infty}{\lim\inf} \frac{1}{T}\sum_{t = 1}^T \left\{ KL(g; \text{M}_0) - KL(g;\text{M}_1) \right\} = \underset{n\rightarrow \infty}{\lim\inf}\ \frac{1}{T}\sum_{t = 1}^T  \left(\frac{\mu^2}{2} - 0\right) > 0
  \]
\end{block}
\begin{block}{Condition on Penalty}
  \begin{itemize}
    \item Need $c_{T,k} = o_p(T)$, i.e.\ $c_{T,k}/T \overset{p}{\rightarrow} 0$.  
    \item Both AIC and BIC satisfy this
    \item If $\mu \neq 0$, both AIC and BIC select $\text{M}_1$ wpa 1 as $T\rightarrow \infty$.
  \end{itemize}
\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Case II: $\mu = 0$}

  \begin{block}{What's different?}
  \begin{itemize}
    \item Both $M_1$ and $M_0$ are true and minimize KL divergence at zero. 
    \item \alert{Consistency} says choose most parsimonious true model: $\text{M}_0$
  \end{itemize}
  \end{block}

  \begin{block}{Verifying Conditions for Consistency}
    Use the second set of sufficient conditions:
    \begin{itemize}
      \item $N(0,1)$ model nested inside $N(\mu,1)$ model
      \item Truth is $N(0,1)$ so LR-stat is asymptotically $\chi^2(1) = O_p(1)$.
      \item For penalty term, need $\mathbb{P}(c_{T,k} - c_{T,0})\rightarrow \infty$
      \item BIC satisfies this but AIC doesn't.
    \end{itemize}
    
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Finite-Sample Selection Probabilities: AIC}
  \begin{block}{AIC Sets $d_T = 2$}


	$$\widehat{M}_{AIC} = \left\{\begin{array}
		{cc} M_1, &|\sqrt{T}\bar{Y}| \geq \sqrt{2} \\
		M_0, & |\sqrt{T} \bar{Y}| < \sqrt{2}
	\end{array} \right.$$
  \end{block}

  \vspace{-2em}

    \footnotesize
	\begin{eqnarray*}
		P\left(\widehat{M}_{AIC} = M_1\right) &=& P\left(\left|\sqrt{T}\bar{Y} \right| \geq \sqrt{2}  \right)\\
		&=& P\left(\left|\sqrt{T}\mu + Z\right| \geq \sqrt{2}  \right)\\
		&=& P\left(\sqrt{T}\mu + Z \leq -\sqrt{2}\right) + \left[1 - P\left(\sqrt{T} \mu +Z \leq \sqrt{2}\right) \right]\\
			&=& \Phi\left(-\sqrt{2} - \sqrt{T}\mu\right) + \left[1 -  \Phi\left(\sqrt{2} - \sqrt{T} \mu \right)\right]
	\end{eqnarray*}

  \normalsize
where $Z \sim N(0,1)$ since $\bar{Y} \sim N(\mu, 1/T)$ because $Var(Y_t)=1$.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Finite-Sample Selection Probabilities: BIC}

  \begin{block}{BIC sets $d_T = \log(T)$}
	$$\widehat{M}_{BIC} = \left\{\begin{array}
		{cc} M_1, & |\sqrt{T}\bar{Y} | \geq \sqrt{\log(T)} \\
		M_0, & |\sqrt{T} \bar{Y}| < \sqrt{\log(T)}
	\end{array} \right.$$
  \end{block}
Same steps as for the AIC except with $\sqrt{\log(T)}$ in the place of $\sqrt{2}$:
\footnotesize
	\begin{eqnarray*}
		P\left(\widehat{M}_{BIC} = M_1\right) &=& P\left(\left|\sqrt{T}\bar{Y} \right| \geq \sqrt{\log(T)}  \right)\\
			&=& \Phi\left(-\sqrt{\log(T)} - \sqrt{T}\mu\right) + \left[1 -  \Phi\left(\sqrt{\log(T)} - \sqrt{T} \mu \right)\right]
	\end{eqnarray*}

  \begin{block}{Interactive Demo: AIC vs BIC}

\url{https://fditraglia.shinyapps.io/CH\_Figure\_4\_1/}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Probability of Over-fitting}

  \small

  \begin{itemize}
    \item If $\mu = 0$ both models are true but $M_0$ is more parsimonious. 
    \item Probability of over-fitting ($Z$ denotes standard normal): 
\begin{eqnarray*}
	P\left(\widehat{M} = M_1\right) &=& P\left(|\sqrt{T}\bar{Y}|\geq \sqrt{d_T}\right) = P(|Z|\geq \sqrt{d_T})\\
	 &=& P(Z^2 \geq d_T) = P(\chi^2_1 \geq d_T)
\end{eqnarray*}
\item AIC: $d_T = 2$ and $P(\chi^2_1 \geq 2)\approx 0.157$.  
\item BIC: $d_T = \log(T)$ and $P(\chi^2_1 \geq \log T) \rightarrow 0$ as $T\rightarrow 0$.
  \end{itemize}

  \alert{AIC has $\approx$ 16\% prob.\ of over-fitting; BIC does not over-fit in the limit.}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Risk of the Post-Selection Estimator}
  \begin{block}{The Post-Selection Estimator}
	$$\widehat{\mu}=\left\{\begin{array}
		{cc} \bar{Y}, & |\sqrt{T}\bar{Y} | \geq \sqrt{d_T} \\
		0, & |\sqrt{T}\bar{Y} | < \sqrt{d_T}
		\end{array}\right.$$
  \end{block}

  \vspace{-2em}

  \begin{block}{Recall from above}
Recall from above that $\sqrt{T} \bar{Y} = \sqrt{T}\mu +Z$ where $Z\sim N(0,1)$
  \end{block}
  \begin{block}{Risk Function}
MSE risk times $T$ since Var.\ of well-behaved estimator $ = O(1/T)$

\[
  R_T(\mu) = T \cdot \mathbb{E}\left[\left( \widehat{\mu} - \mu\right)^2\right] = \mathbb{E}\left[\left(\sqrt{T} \widehat{\mu} - \sqrt{T} \mu\right)^2\right] 
\]
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Simplifying the MSE Risk Function}
  \framesubtitle{$\sqrt{T} \bar{Y} = \sqrt{T}\mu +Z$ where $Z\sim N(0,1)$}

  \footnotesize

  Let $X = \mathbf{1}\left\{ A \right\}$ where $A = \left\{|\sqrt{T}\mu + Z|\geq \sqrt{d_T}  \right\}$
  \begin{eqnarray*}
  R_T(\mu) &=& \mathbb{E}\left[\left(\sqrt{T} \widehat{\mu} - \sqrt{T} \mu\right)^2\right] \\
  &=& \mathbb{E}\left\{ \left[ \left( \sqrt{T}\mu + Z \right)X - \sqrt{T}\mu \right]^2 \right\}\\
  &=& \mathbb{P}(A)\; \mathbb{E}\left\{ \left.\left[ \left(\sqrt{T}\mu + Z\right) - \sqrt{T}\mu\right]^2\right| X = 1 \right\} + \left[ 1 - \mathbb{P}(A) \right]\left( \sqrt{T}\mu \right)^2\\
  &=& \mathbb{P}(A)\; \mathbb{E}
  \left[ Z^2 |X = 1 \right] + \left[ 1 - \mathbb{P}(A) \right]T\mu^2
\end{eqnarray*}

\alert{So we need to calculate $\mathbb{P}(A)\; \mathbb{E}[Z^2|X=1]$ and $\mathbb{P}(A)$.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Calculating $\mathbb{P}(A)$}
  Define $a = (-\sqrt{d_T} - \sqrt{T}\mu)$ and $b = (\sqrt{d_T} - \sqrt{T}\mu)$ 

  \begin{eqnarray*}
    \mathbb{P}(A) &=& \mathbb{P}\left( |\sqrt{T}\mu + Z| \geq \sqrt{d_T} \right) \\
    &=& \mathbb{P}\left( \sqrt{T}\mu + Z \geq \sqrt{d_T} \right) + \mathbb{P}\left( \sqrt{T}\mu + Z \leq -\sqrt{d_T} \right) \\
    &=& \mathbb{P}(Z\geq b) + \mathbb{P}(Z \leq a)\\
    &=& 1 - \Phi(b) + \Phi(a)
  \end{eqnarray*}

  And hence:
  \[
    1 - \mathbb{P}(A) = \Phi(b) - \Phi(a)
  \]
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Calculating $\mathbb{P}(A)\;\mathbb{E}[Z^2|X=1]$ -- Step 1}
  \begin{block}{Conditional Density of $Z|X=1$}
    \vspace{-1em}
    \[f(z|x=1) = \frac{\mathbf{1}(A)\varphi(z)}{\mathbb{P}(A)} \quad \text{where } \varphi \text{ is the } N(0,1) \text{ density} \]
  \end{block}

  \begin{block}{Therefore:}
    \begin{eqnarray*}
      \mathbb{P}(A)\; \mathbb{E}[Z^2|X=1] &=& \mathbb{P}(A) \int_{\mathbb{R}} z^2 \left[ \frac{\mathbf{1}(A)\varphi(z)}{\mathbb{P}(A)} \right]\; \text{d}z\\ 
       &=&  \int_{-\infty}^a z^2 \varphi(z)\; \text{d}z + \int_{b}^\infty z^2 \varphi(z)\; \text{d}z\\ 
    \end{eqnarray*}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Calculating $\mathbb{P}(A)\; \mathbb{E}[Z^2|X=1]$ -- Step 2}
  \begin{block}{Unconditional Expectation: $\mathbb{E}[Z^2]$}
    \[
      1 = \mathbb{E}[Z^2]  = 
      \int_{-\infty}^a z^2 \varphi(z)\; \text{d}z +
      \int_{a}^b z^2 \varphi(z)\; \text{d}z +
      \int_{b}^\infty z^2 \varphi(z)\; \text{d}z
    \]
  \end{block}

  \begin{block}{Therefore:}
    \begin{eqnarray*}
      \mathbb{P}(A)\; \mathbb{E}[Z^2|X=1] &=&  \int_{-\infty}^a z^2 \varphi(z)\; \text{d}z + \int_{b}^\infty z^2 \varphi(z)\; \text{d}z\\ 
       &=& 1 - \int_a^b z^2 \varphi(z)\; \text{d}z
    \end{eqnarray*}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Calculating $\mathbb{P}(A)\;\mathbb{E}[Z^2|X=1]$ -- Step 3}

  \vspace{1em}

  \begin{block}{Integration By Parts}
  \small 
Take $u = -z$ and $dv = -z \exp\{-z^2/2\}$ since

	$$\frac{d}{dz} \left(\exp\left\{-z^2/2\right\}\right) = -z\exp\left\{-z^2/2\right\}$$

  \vspace{0.5em}

Thus, $v = \exp\{-z^2/2\}$, $du = -1$ and 
\begin{eqnarray*}
  \int_a^b z^2 \phi(z) \; dz &=& \left( 2\pi \right)^{-1/2} \int_a^b z^2 \exp\left\{-z^2/2 \; \right\} \;\text{d}z\\
  &=& \left( 2\pi \right)^{-1/2}\left[-z \exp\left\{ \left.-z^2/2\right\}\right|_a^b+ \int_a^b \exp\left\{-\frac{z^2}{2}\right\}  \; dz \right]\\
		&=& a\phi(a) - b\phi(b) + \Phi(b) - \Phi(a)
\end{eqnarray*}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplifed MSE Risk Function}
	\begin{eqnarray*}
		R_T(\mu) &=& 1 - \left[a\phi(a) - b\phi(b) + \Phi(b) - \Phi(a) \right] + T\mu^2 \left[\Phi(b) - \Phi(a) \right]\\
		&=&1 + \left[b\phi(b) - a\phi(a)\right]  + (T\mu^2 - 1) \left[\Phi(b) - \Phi(a) \right] 
	\end{eqnarray*}
where
	\begin{eqnarray*}
		a &=& -\sqrt{d_T} - \sqrt{T}\mu\\
		b &=& \sqrt{d_T} - \sqrt{T}\mu
	\end{eqnarray*}

\url{https://fditraglia.shinyapps.io/CH\_Figure\_4\_2/}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Punchline: Risk of the Post-Selection Estimator}

  \begin{itemize}
    \item AIC: bounded worst-case risk
    \item BIC: low risk in a neighborhood of $\mu=0$ in exhange for \alert{unbounded} worst-case risk as sample size grows
    \item General phenomenon: consistency and efficiency are mutually exclusive: consistent criteria have unbounded worst-case risk.
    \item For more details, see Yang (2007, ET)
  \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
