\documentclass[handout]{beamer}  

%Smaller gap at between top and bottom of block when there are displayed equations
\addtobeamertemplate{block begin}{\setlength\abovedisplayskip{0pt}}
{\setlength{\belowdisplayskip}{0pt}}


\usepackage{setspace}
\linespread{1.2}
\usepackage{amssymb, amsmath, amsthm} 
\usepackage{rotating}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{synttree}
\usepackage{verbatim}
\usepackage{fancybox}
\usepackage{color}
\usepackage{tikz}
\usetikzlibrary{shapes,backgrounds}
\usepackage{hyperref}
\usetikzlibrary{trees}
\newcommand{\p}{\mathbb{P}}
\newcommand{\expect}{\mathbb{E}}


%\setbeamertemplate{blocks}[rounded][shadow=true] 
%gets rid of bottom navigation bars
\setbeamertemplate{footline}{
   \begin{beamercolorbox}[ht=4ex,leftskip=0.3cm,rightskip=0.3cm]{author in head/foot}
%    \usebeamercolor{UniBlue}
    \vspace{0.1cm}
    %\insertshorttitle \ - \insertdate 
    \hfill \insertframenumber / \inserttotalframenumber
   \end{beamercolorbox}
   \vspace*{0.1cm}
} 

%Put the math in red
\setbeamercolor{math text}{fg=red}

%gets rid of navigation symbols
\setbeamertemplate{navigation symbols}{}


%Include or exclude the notes?
%\setbeameroption{show notes}
\setbeameroption{hide notes}

\title[Econ 722]{High Dimensional Forecasting} 
\author[F. DiTraglia]{Francis J.\ DiTraglia}
\institute{University of Pennsylvania}
\date{Econ 722}


\begin{document} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}[plain]
	\titlepage 
	

\end{frame} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{What Have We Learned So Far?}
    
    \begin{enumerate}
    	\item Classical Model Selection
    	\item Focused Model Selection
    	\item Moment Selection for GMM
    	\item Shrinkage Estimation
    	\item Factor Models
    \end{enumerate}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Today's Lecture -- A Bit of a Grab Bag}
    
``Tie everything together'' by looking at high-dimensional forecasting problems, consider some avenues for future research. Also give a brief overview of some topics I had hoped to cover in more detail but didn't have time for.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{What's Different About High-Dimensional Problems?}
    
\begin{itemize}
	\item OLS performs very badly if the number of regressors is large relative to sample size.
	\item Estimation uncertainty can be a problem
	\item Noise accumulation in PCA: that Fan and Li paper, also Boivin \& Ng
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Main References}
	\begin{block}
		{Stock \& Watson (2006) -- ``Forecasting with Many Predictors''} Overview of high-dimesional forecasting with a review of forecast combination, factor models, and Bayesian approaches.
	\end{block}
	\begin{block}
		{Ng (2013) -- ``Variable Selection in Predictive Regressions''}
		Reviews and relates a number of shrinkage \& selection methods.
	\end{block}
	\begin{block}
		{Stock \& Watson (2012)}
	\end{block}
	\begin{block}
		{Kim \& Nelson (2013)}
	\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Diffusion Index Forecasting -- Stock \& Watson (2002a,b)}
 \framesubtitle{JASA paper has the theory, JBES paper has macro forecasting example.}

\begin{block}
	{Basic Setup}
	Forecast scalar time series $y_{t+1}$ using $N$-dimensional collection of time series $X_t$ where we observe periods $t = 1, \hdots, T$.
\end{block}

\begin{block}
	{Assumption}
	Static representation of Dynamic Factor Model:
	\begin{eqnarray*}
		y_{t}&\alert{=}& \beta' F_t + \gamma(L)y_t + \epsilon_{t+1}\\
		\alert{X_t} &\alert{=}& \alert{\Lambda F_t + e_t}
	\end{eqnarray*}
\end{block}

\begin{block}
	{``Direct'' Multistep Ahead Forecasts}
	``Iterated'' forecast would be linear in $F_t$, $y_t$ and lags:
	$$y_{t+h}^h = \alpha_h + \beta_h(L) + \gamma_h(L)+ \gamma_h(L)y_t + \epsilon^h_{t+h}$$
\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\begin{center}
	\Huge This is really just PCR
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Diffusion Index Forecasting -- Stock \& Watson (2002a,b)}
    
    \begin{block}
    	{Estimation Procedure}
    	\begin{enumerate}
    		\item Data Pre-processing
    			\begin{enumerate}
    			\item Transform all series to stationarity (logs or first difference)
				\item Center and standardize all series
				\item Remove outliers (ten times IQR from median)
				\item Optionally augment $X_t$ with lags
    			\end{enumerate}
    		\item Estimate the Factors
    			\begin{itemize}
    				\item No missing observations: PCA on $X_t$ to estimate $\widehat{F}_t$ 
		\item Missing observations/Mixed-frequency: EM-algorithm
    			\end{itemize}
    		\item Fit the Forecasting Regression
    		\begin{itemize}
    			\item Regress $y_{t}$ on a constant and lags of $\widehat{F}_t$ and $y_t$ to estimate the parameters of the ``Direct'' multistep forecasting regression.
    		\end{itemize}
    	\end{enumerate}
    \end{block}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Diffusion Index Forecasting -- Stock \& Watson (2002b)}
    
\alert{Recall from last time that, under certain assumptions, PCA consistently estimates the space spanned by the factors. Broadly similar assumptions are at work here.}

\vspace{2em}

\begin{block}
	{Main Theoretical Result}
	Moment restrictions on $(\epsilon, e, F)$ plus a ``rank condition'' on $\Lambda$ imply that the MSE of the procedure on the previous slide converges to that of the infeasible optimal procedure, provided that  $N,T \rightarrow \infty$.
\end{block}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Diffusion Index Forecasting -- Stock \& Watson (2002a)}
    
\begin{block}
	{Forecasting Experiment}
	\begin{itemize}
		\item Simulated real-time forecasting of eight monthly macro variables from 1959:1 to 1998:12
		\item Forecasting Horizons: 6, 12, and 24 months
		\item ``Training Period'' 1959:1 through 1970:1
		\item Predict $h$-steps ahead out-of-sample, roll and re-estimate.
		\item BIC to select lags and \# of Factors in forecasting regression
		\item Compare Diffusion Index Forecasts to Benchmark
			\begin{itemize}
				\item AR only
				\item Factors only
				\item AR + Factors
			\end{itemize}
	\end{itemize}
\end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Diffusion Index Forecasting -- Stock \& Watson (2002a)}
   \begin{block}
   	{Empirical Results}
   	\begin{itemize}
   		\item Factors provide a substantial improvement over benchmark forecasts in terms of MSPE
   		\item Six factors explain 39\% of the variance in the 215 series; twelve explain 53\%  
   		\item Using all 215 series tends to work better than restricting to balanced panel of 149 (PCA estimation)
   		\item Augmenting $X_t$ with lags isn't helpful
   	\end{itemize}
   \end{block}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Another Line of Research on Factor Models}

The assumption of a factor structure sure is convenient, but how does it relate to other kinds of assumptions we're more familiar with? (e.g.\ everything follows a VAR). Does this structure come out of our economic models, or is it just an assumption of convenience? I haven't seen much work on this, but it seems important to me. Two recent papers that consider questions along these lines: Onatski and Ruge (2012), Dufour \& Stevanovic
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{What about Ridge and Lasso}
    
Diffusion Index is really just PCR. What about Ridge and Lasso? Rather than extract factors, just do penalized forecasting regression and ``toss everything in.''

De Mol, Giannone \& Reichlin (2008) -- Compare performance of Ridge and Lasso to PCA-based forecasts (PCR). Small out-of-sample experiment Same data as Stock \& Watson 2005 -- implications of Dynamic Factors for VAR analysis). With appropriate choice of penalty parameters, Ridge and Lasso forecasts performance similar to that of Diffusion Index (PCR). Analyze asymptotic behavior of ridge under the assumptions used to justify PCA by Stock \& Watson inter alia. 

Talk more about this looking at the two more recent papers.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Other Ways of Extracting Factors}
    
Bai and Ng targeted predictors paper adds transformations of original series. (Talk more about this in relation to kernel stuff). To target or not to target? Why should the PCs of $X$ be related to $Y$? Lots of ways to target. Bai and Ng as well as PLS Groen \& Kapetanios, Kelly \& Pruitt. Sparse PCA, ICA.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Kernel Methods}
   
   Hasn't been explored much in econometrics, but very popular in machine learning. One recent econometrics paper is Exterkate et al (2013) ``Nonlinear Forecasting with Many Predictors Using Kernel Ridge Regression''


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Bootstrap Aggregation -- ``Bagging''}
    
    % Inoue \& Killian among others. Designed to ``smooth out'' discrete stuff (e.g.\ variable selection or LASSO) to reduce variance. General procedure although most econometrians examine an asymptotic approximation to a special version of the procedure (based on a pre-test with size 0.05) rather than considering it in more generality.

\begin{block}
	{Bagging Algorithm}
	\begin{enumerate}
		\item Make a bootstrap draw  
		\item Carry out selection/shrinkage/estimation using boostrap data
		\item Use estimated parameters from to construct a forecast $\widehat{y}_{T+h}^{(b)}$
		\item Repeat for $b = 1, \hdots, B$
		\item Average to get ``Bagged'' Forecast: $\widehat{y}_{T+h}^{(Bag)} = \frac{1}{B}\sum_{b=1}^B \widehat{y}_{T+h}^{(b)}$
	\end{enumerate}
\end{block}

\begin{block}
	{Details}
	\begin{itemize}
		\item If the data are dependent, need block bootstrap.
		\item In step 3, we forecast using the \emph{parameters} estimated from the bootstrap data but the \emph{predictors} from the \emph{real} dataset.
	\end{itemize}
\end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Bootstrap Aggregation -- ``Bagging''}

\begin{block}
 	{Why Bagging?}
 		\begin{itemize}
 			\item Aims to reduce the forecast error of ``unstable'' procedures such as variable selection of Lasso, by reducing their variance.
 			\item Completely portable, provided you have an appropriate way to carry out the bootstrap.
 			\item May provide a way of attacking the problem of inference post-model selection. See Efron (JASA, \emph{Forthcoming}) ``Estimation and Accuracy after Model Selection''
 		\end{itemize}
 \end{block} 


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Bagging in Economics}
	\begin{block}
		{Inoue \& Killian (2008, JASA)}
		Compares performance of bagged ``pre-test'' estimator (variable selection via a t-test) to other methods of forecasting US Inflation. Bagging is carried out via a block bootstrap.
	\end{block}
	\begin{block}
		{Stock \& Watson (2012)}
		Among other shrinkage procedures, they consider a large-sample approximation to bagging pre-test estimators that doesn't require making bootstrap draws.
	\end{block}
	\begin{block}
		{Other Papers That Use Bagging}
		\begin{itemize}
			\item Hillebrand \& Medeiros (2010): Realized Volatility Forecasts
			\item Hillebrand et al (2012): Forecasting the Equity Premium
			\item \alert{Kim and Swanson (2013)}
		\end{itemize}
	\end{block}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{Bai \& Ng (2009) -- Boosting Diffusion Indices}
    
Also, Buchen \& Wohlrabe (2011) -- boosting compared to the Stock and Watson 2006 example.

We'll learn more about boosting in the student presentations!
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[c]\frametitle{What Should We Make of This Literature}
    \footnotesize
\begin{itemize}
	\item Shrinkage is essential in high-dimensional problems and often beats model averaging.
	\item There's no single best procedure for every problem
	\item Worth considering new ways of extracting factors \& combining with shrinkage
	\item How and when should we target? Relationship to spurious correlation and overfitting? There are strong opinions on both sides, but I haven't seen any compelling justifications.
	\item No one has any idea what's going on with model selection for these problems: generated regressors, target-specific, consistency vs. efficiency. Onatski paper is one contribution but it deals with a somewhat odd version of the problem: forecasting the whole $X_t$
	\item Want shrinkage to be data-driven. There are results on rates for consistency of Lasso, etc, but that's not what we care about for forecasting. People just use the default CV procedure in matlab (or R) which has no justification in the time-series setting. 
	\item Two-step procedures, generated regressors.
	\item Inference is very hard post-selection and for shrinkage estimation (unless you're a Bayesian). There is a paper on this for the factors by Bai \& Ng.
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}